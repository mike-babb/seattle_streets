{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed9e25b-c5b9-4aee-89cd-15a7da3945c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mike babb\n",
    "# 2024 06 28\n",
    "# what streets start and stop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88ca8b2-b75d-4e72-8fc7-65c4cea61cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0778d9a5-0c62-4724-be28-c21598d23b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# external\n",
    "from itertools import combinations, product\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString, Point\n",
    "from shapely import line_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc61400-c637-4828-820d-56c2cdd14942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom\n",
    "from geodataio.geo_operations import points2distance, calculate_initial_compass_bearing\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ea77e-ffd7-4326-b793-415f8a131ef2",
   "metadata": {},
   "source": [
    "# load the working seattle street network data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07cfb9b-9184-48d7-af77-035e2390d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "input_file_path = 'H:/project/seattle_streets/data/' \n",
    "output_file_path = 'H:/project/seattle_streets/data/individual_streets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c1039f5-a281-4460-b65d-98a6ca2556b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Street_Network_Database_Seattle_working.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf62724-9105-44c9-b983-e4f520328fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn = os.path.join(input_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cbdb5c1-c973-4882-b442-cf5396e90d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(filename = fpn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee171e0-b275-4f73-9ec5-e8a2a718d55d",
   "metadata": {},
   "source": [
    "# load the node data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a99446f1-9603-4f7f-80e2-a2d8a10f8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = 'Street_Network_Nodes.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81e88fff-cc66-47fd-bc60-fb253a9f110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn = os.path.join(input_file_path, input_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e67fed54-4d3b-45ca-8a41-2f9e7103a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_gdf = gpd.read_file(filename = fpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26bac731-425e-409f-bb41-c3a5d1a6bf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17740</td>\n",
       "      <td>POINT (-122.32287 47.52982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11391</td>\n",
       "      <td>POINT (-122.32402 47.61849)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>982</td>\n",
       "      <td>POINT (-122.29193 47.7649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11695</td>\n",
       "      <td>POINT (-122.30782 47.61411)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6257</td>\n",
       "      <td>POINT (-122.38214 47.67456)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id                     geometry\n",
       "0    17740  POINT (-122.32287 47.52982)\n",
       "1    11391  POINT (-122.32402 47.61849)\n",
       "2      982   POINT (-122.29193 47.7649)\n",
       "3    11695  POINT (-122.30782 47.61411)\n",
       "4     6257  POINT (-122.38214 47.67456)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65c710c8-40db-4bc0-af3a-78c6c64e495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_gdf['coords'] = node_gdf['geometry'].map(lambda x: x.coords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac7dff3c-6d52-4b80-b259-2214ef6c131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17740</td>\n",
       "      <td>POINT (-122.32287 47.52982)</td>\n",
       "      <td>(-122.32287444824671, 47.529819957875)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11391</td>\n",
       "      <td>POINT (-122.32402 47.61849)</td>\n",
       "      <td>(-122.32401964037119, 47.61848906651073)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>982</td>\n",
       "      <td>POINT (-122.29193 47.7649)</td>\n",
       "      <td>(-122.29192836110747, 47.764904310419276)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11695</td>\n",
       "      <td>POINT (-122.30782 47.61411)</td>\n",
       "      <td>(-122.30781531879083, 47.61410595110372)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6257</td>\n",
       "      <td>POINT (-122.38214 47.67456)</td>\n",
       "      <td>(-122.38214200036303, 47.67455801597557)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id                     geometry  \\\n",
       "0    17740  POINT (-122.32287 47.52982)   \n",
       "1    11391  POINT (-122.32402 47.61849)   \n",
       "2      982   POINT (-122.29193 47.7649)   \n",
       "3    11695  POINT (-122.30782 47.61411)   \n",
       "4     6257  POINT (-122.38214 47.67456)   \n",
       "\n",
       "                                      coords  \n",
       "0     (-122.32287444824671, 47.529819957875)  \n",
       "1   (-122.32401964037119, 47.61848906651073)  \n",
       "2  (-122.29192836110747, 47.764904310419276)  \n",
       "3   (-122.30781531879083, 47.61410595110372)  \n",
       "4   (-122.38214200036303, 47.67455801597557)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d26b04eb-ebbf-4b3c-a2a2-f7e5604a695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zap this into a dictionary\n",
    "node_dict = {}\n",
    "for i, row in node_gdf.iterrows():\n",
    "    node_dict[row['node_id']] = row['coords']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc818f-24c9-4a7d-8f33-e516cde7dd55",
   "metadata": {},
   "source": [
    "# FIND MISSING SEGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f66e8c67-7363-44b2-a812-f7c38d5619b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight variable from the gis_segment_length variable\n",
    "gdf['weight'] = gdf['gis_seg_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51c24465-4495-45ab-a5af-ecfb81610d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY SELECT COLUMNS NAMES USED IN SUBSEQUENT STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58d63e28-b0e3-4643-aa49-e14e498065fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['f_intr_id',\n",
    "'t_intr_id',\n",
    "'snd_id',\n",
    "'snd_feacode',\n",
    "'gis_seg_length',\n",
    "'ord_street_name',\n",
    "'ord_street_type',\n",
    "'ord_stname_concat',\n",
    "'city_portion',\n",
    "'geometry',\n",
    "'weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6d7fd5a-93e1-47de-96e0-29eebc7e4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf[col_names].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4fd3741-90de-47be-8f70-95b5dec11555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5fab916-d87a-4d24-b079-7ac593c4bfc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERRILL LN NW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babbm\\AppData\\Local\\Temp\\ipykernel_16324\\3429075960.py:115: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_gdf = pd.concat([ms_gdf, ks_gdf])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W LAWTON CIR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babbm\\AppData\\Local\\Temp\\ipykernel_16324\\3429075960.py:115: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_gdf = pd.concat([ms_gdf, ks_gdf])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7TH AVE N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babbm\\AppData\\Local\\Temp\\ipykernel_16324\\3429075960.py:115: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_gdf = pd.concat([ms_gdf, ks_gdf])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEWARD PARK RD\n",
      "NE RADFORD DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babbm\\AppData\\Local\\Temp\\ipykernel_16324\\3429075960.py:115: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_gdf = pd.concat([ms_gdf, ks_gdf])\n",
      "C:\\Users\\babbm\\AppData\\Local\\Temp\\ipykernel_16324\\3429075960.py:115: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_gdf = pd.concat([ms_gdf, ks_gdf])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE WAHKIAKUM LN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babbm\\AppData\\Local\\Temp\\ipykernel_16324\\3429075960.py:115: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_gdf = pd.concat([ms_gdf, ks_gdf])\n"
     ]
    }
   ],
   "source": [
    "# save intermediate data for checking?\n",
    "write_intermediate = False\n",
    "\n",
    "# hold the output\n",
    "output_gdf_list = []\n",
    "gdf['snd_group'] = int(0)\n",
    "snd_group_count = -1\n",
    "# get the list of unique names\n",
    "s_name = gdf['ord_stname_concat'].unique().tolist()\n",
    "#s_name = ['W LAWTON ST']\n",
    "trouble_list = []\n",
    "for sn in s_name[:None]:\n",
    "    #print(sn)\n",
    "    # subset the gdf by streetname\n",
    "    temp_gdf = gdf.loc[gdf['ord_stname_concat'] == sn, :].copy()\n",
    "    \n",
    "    # create the graph for a single street. For example, all streets W GALER ST are a single graph\n",
    "    fg = nx.from_pandas_edgelist(df = temp_gdf, source = 'f_intr_id', target = 't_intr_id', edge_attr=True)\n",
    "    node_list = list(fg.nodes)\n",
    "    \n",
    "    # a list of the snd groups - this is necessary to match street segments to nodes\n",
    "    # nx.connected_components() identifies disconnected graphs\n",
    "    for cc in nx.connected_components(G = fg):\n",
    "        # cc is the sub graph\n",
    "        # this is the edge data\n",
    "        edge_data_list = fg.subgraph(cc).edges.data()\n",
    "        # this marks the street(s) in each sub graph\n",
    "        snd_id_list = []\n",
    "        for edl in edge_data_list:                        \n",
    "            snd_id_list.append(edl[2]['snd_id'])\n",
    "        snd_group_count += 1\n",
    "        # this will update the gdf per street name with the groups of streets\n",
    "        temp_gdf.loc[temp_gdf['snd_id'].isin(snd_id_list), 'snd_group'] = snd_group_count     \n",
    "    \n",
    "    snd_group_id_list = temp_gdf['snd_group'].unique()        \n",
    "    \n",
    "    if len(snd_group_id_list) > 1:\n",
    "        # process for separate sub graphs\n",
    "        node_snd_group_dict = {}\n",
    "        # a node - an intersection - can have more than one street.\n",
    "        # we need to update the node snd group dict for every street\n",
    "        for ir, row in temp_gdf.iterrows():       \n",
    "            fn = row['f_intr_id']\n",
    "            tn = row['t_intr_id']\n",
    "            snd_group_id = row['snd_group']\n",
    "            node_snd_group_dict[fn] = snd_group_id\n",
    "            node_snd_group_dict[tn] = snd_group_id                                             \n",
    "        \n",
    "        # create a list of available edges - these are the missing segments\n",
    "        # these are formed from the non-edges of the graph.        \n",
    "        avail_edges = []\n",
    "        # dictionary to hold available edges\n",
    "        # let's only make the distance calculation once, yeah?\n",
    "        # it's a simple calculation, but even more simple to store it. \n",
    "        node_dist_dict = {}\n",
    "        # enumerate the non-edges\n",
    "        for ne in nx.non_edges(graph = fg):    \n",
    "            # ne is a tuple of from / to nodes.\n",
    "            # create available edges if the nodes are not on the same segment\n",
    "            # this will decrease the potential solution space\n",
    "            if node_snd_group_dict[ne[0]] != node_snd_group_dict[ne[1]]:\n",
    "                # calculate the straight-line distance between two nodes. \n",
    "                # convert to feet to match the existing distance / weight\n",
    "                weight = points2distance(node_dict[ne[0]], node_dict[ne[1]], unit = 'miles') * 5280\n",
    "                # build the output tuple\n",
    "                output = (ne[0], ne[1], {'weight':weight})\n",
    "                # add to the distance dict\n",
    "                node_dist_dict[(ne[0], ne[1])] = weight \n",
    "                node_dist_dict[(ne[1], ne[0])] = weight \n",
    "                avail_edges.append(output)\n",
    "\n",
    "        # these are missing segments.\n",
    "        # nx.k_edge_augmentation creates the missing edges in a graph by adding as\n",
    "        # few edges as possible. In a street network, with multiple disconnected\n",
    "        # components, there is really one way to minimally connect the disparate components\n",
    "        # to create full connectivity. And it's the shortest geographic segment in this case!\n",
    "        # weighted graph traversal works by accumulating as little weight as possible. \n",
    "        \n",
    "        data_list = []\n",
    "        line_list = []\n",
    "        # once nx.k_edge_augmentation finishes, it returns a generator with the added edges that\n",
    "        # ensure complete connectivity between all nodes.\n",
    "        augmented_edges = nx.k_edge_augmentation(G = fg, k = 1, avail = avail_edges, weight = 'weight')    \n",
    "        # enumberat\n",
    "        for i_ae, ae in enumerate(augmented_edges):\n",
    "            # unpack\n",
    "            fn, tn = ae            \n",
    "            # get the weight / distance of the added edge\n",
    "            weight = node_dist_dict[(fn, tn)] \n",
    "            # this is the output dictionary\n",
    "            # street name, integer indicating the snd_group, from node, to node, distance of the edge\n",
    "            temp_data_list = [sn, i_ae, fn, tn, weight]\n",
    "            # now, let's create some geometry\n",
    "            temp_line = LineString([node_dict[fn], node_dict[tn]])\n",
    "            line_list.append(temp_line)\n",
    "            data_list.append(temp_data_list)\n",
    "\n",
    "        # build a gpd.GeoDataFrame - these are the \"missing\" segments\"\n",
    "        ms_gdf = gpd.GeoDataFrame(data = data_list,\n",
    "                                         columns = ['ord_stname_concat', 'snd_group', 'sn_id', 'en_id', 'dist'],\n",
    "                                         geometry = line_list, crs = 'epsg:4326')\n",
    "        # these edges are not on the same street group\n",
    "        ms_gdf['same_snd_group'] = int(0)\n",
    "        if ms_gdf.empty:\n",
    "            trouble_list.append(sn)\n",
    "            print(sn)\n",
    "        \n",
    "        # now, we need to get the known segments\n",
    "        col_names = ['ord_stname_concat', 'snd_group',  'f_intr_id', 't_intr_id', 'gis_seg_length', 'geometry']    \n",
    "        ks_gdf = temp_gdf[col_names].copy()\n",
    "        ks_gdf['same_snd_group'] = int(1)\n",
    "        ks_gdf = ks_gdf.rename(columns = {'f_intr_id':'sn_id', 't_intr_id':'en_id', 'gis_seg_length':'dist'})\n",
    "\n",
    "        # stack the geodataframes\n",
    "        output_gdf = pd.concat([ms_gdf, ks_gdf])\n",
    "    \n",
    "        # write intermediate\n",
    "        if write_intermediate:\n",
    "            # intermediate streets\n",
    "            output_file_name = '_'.join(sn.split()) + '.gpkg'\n",
    "            write_gdf(gdf = temp_gdf, output_file_path = output_file_path, output_file_name = output_file_name)\n",
    "        \n",
    "            # intermediate nodes\n",
    "            curr_node_df = pd.DataFrame(data = {'node_id':fg.nodes()})\n",
    "            curr_node_list = curr_node_df['node_id'].tolist()\n",
    "            node_subset_gdf = subset_node_gdf(node_gdf = node_gdf, other_node_df = curr_node_df)\n",
    "            output_file_name = 'full_nodes_' + '_'.join(sn.split()) + '.gpkg'\n",
    "            write_gdf(gdf = node_subset_gdf, output_file_path = output_file_path, output_file_name = output_file_name)\n",
    "\n",
    "            # the missing and known segments for a street\n",
    "            output_file_name = 'missing_segments_' + '_'.join(sn.split()) + '.gpkg'\n",
    "            ofpn = os.path.join(output_file_path, output_file_name)                \n",
    "            output_gdf.to_file(filename = ofpn, driver = 'GPKG', index = False)       \n",
    "\n",
    "    else:\n",
    "        # gather the streets with no missing segments.         \n",
    "        col_names = ['ord_stname_concat', 'snd_group', 'f_intr_id', 't_intr_id', 'gis_seg_length', 'geometry']    \n",
    "        output_gdf = temp_gdf[col_names].copy()\n",
    "        output_gdf['same_snd_group'] = int(-1)\n",
    "        output_gdf = output_gdf.rename(columns = {'f_intr_id':'sn_id', 't_intr_id':'en_id', 'gis_seg_length':'dist'})\n",
    "\n",
    "    # add to the output list\n",
    "    output_gdf_list.append(output_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af812042-ad12-47fd-97de-951c86281c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b7caa23-d226-459d-b3cd-f9a9fc2afe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gdf = pd.concat(objs = output_gdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55e02e89-c290-45e0-8893-cc96771a6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gdf['dist_miles'] = ms_gdf['dist'] / 5280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e959e160-ab87-4f4d-89c1-9b1edef0bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join in other street indentification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3d3f481-c567-4d2b-9f11-5b8795ab3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gdf = pd.merge(left = ms_gdf, right = gdf[['ord_stname_concat', 'ord_street_type', 'ord_street_name']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35ebf374-f505-4c9f-8129-1047081af981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30524, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b9ca561-a08b-4732-a62e-17eef306cca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord_stname_concat [False]\n",
      "snd_group [False]\n",
      "sn_id [False]\n",
      "en_id [False]\n",
      "dist [False]\n",
      "geometry [False]\n",
      "same_snd_group [False]\n",
      "dist_miles [False]\n",
      "ord_street_type [False]\n",
      "ord_street_name [False]\n"
     ]
    }
   ],
   "source": [
    "for cn in ms_gdf.columns:\n",
    "    print(cn, ms_gdf[cn].isna().unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3766617b-52fa-4f04-992e-457b9343b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "col_names = ['ord_street_name','ord_stname_concat','ord_street_type','snd_group',\n",
    "             'same_snd_group','sn_id','en_id','dist','dist_miles','geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d849621-4392-415b-894a-4dcc9dfc7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gdf = ms_gdf[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ee38afd-08cb-4eae-b1c9-ec5b16865f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b821c98-17dc-4529-a560-cc278daf1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'H:/project/seattle_streets/data'\n",
    "output_file_name = 'missing_segments.gpkg'\n",
    "ofpn = os.path.join(output_file_path, output_file_name)    \n",
    "\n",
    "ms_gdf.to_file(filename = ofpn, driver = 'GPKG', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89bb5274-293a-41f6-b1ee-2149f8eb45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's causing me grief?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c78c510f-c701-411d-af0d-9d90512c9897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MERRILL LN NW',\n",
       " 'W LAWTON CIR',\n",
       " '7TH AVE N',\n",
       " 'SEWARD PARK RD',\n",
       " 'NE RADFORD DR',\n",
       " 'NE WAHKIAKUM LN']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouble_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18b1a7-41c8-464b-909c-835ea3b17f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
